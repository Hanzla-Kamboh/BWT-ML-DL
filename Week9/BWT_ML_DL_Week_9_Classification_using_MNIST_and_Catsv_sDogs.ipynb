{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkssYl9nEp5D",
        "outputId": "34bf71d6-5289-445e-846f-8f1bd2b0624d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/Colab Notebooks/Datasets/mnist.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall(path='./data')\n",
        "  print('Done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-os2rOxZiGFg",
        "outputId": "aacf20c2-32db-43c2-9f56-881ec7cbc437"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load the training data\n",
        "with open('./data/train-images-idx3-ubyte/train-images-idx3-ubyte', 'rb') as f:\n",
        "    train_images = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
        "    train_images = train_images.reshape(-1, 28, 28)\n",
        "\n",
        "with open('./data/train-labels-idx1-ubyte/train-labels-idx1-ubyte', 'rb') as f:\n",
        "    train_labels = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "# Load the test data\n",
        "with open('./data/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte', 'rb') as f:\n",
        "    test_images = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
        "    test_images = test_images.reshape(-1, 28, 28)\n",
        "\n",
        "with open('./data/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte', 'rb') as f:\n",
        "    test_labels = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "# Print the shapes of the data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the first 5 training images\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(train_images[i], cmap='gray')\n",
        "    plt.title(train_labels[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Display the first 5 test images\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(test_images[i], cmap='gray')\n",
        "    plt.title(test_labels[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "gjd8yHEnjcED",
        "outputId": "47983ae2-60b6-4031-ce95-79933365fba4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images shape: (60000, 28, 28)\n",
            "Train labels shape: (60000,)\n",
            "Test images shape: (10000, 28, 28)\n",
            "Test labels shape: (10000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_onehot = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels_onehot = tf.keras.utils.to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "3gZU9D7omU-F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels_onehot, epochs=10, batch_size=128, validation_data=(test_images, test_labels_onehot), callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "pTZEjhNSk4tt",
        "outputId": "17d49365-70f2-41b8-b281-1d3373069ca1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 126ms/step - accuracy: 0.8088 - loss: 4.3542 - val_accuracy: 0.9738 - val_loss: 0.0904\n",
            "Epoch 2/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 113ms/step - accuracy: 0.9795 - loss: 0.0683 - val_accuracy: 0.9788 - val_loss: 0.0731\n",
            "Epoch 3/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 117ms/step - accuracy: 0.9859 - loss: 0.0445 - val_accuracy: 0.9867 - val_loss: 0.0540\n",
            "Epoch 4/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.9906 - loss: 0.0299 - val_accuracy: 0.9865 - val_loss: 0.0484\n",
            "Epoch 5/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 111ms/step - accuracy: 0.9935 - loss: 0.0207 - val_accuracy: 0.9864 - val_loss: 0.0550\n",
            "Epoch 6/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 115ms/step - accuracy: 0.9934 - loss: 0.0194 - val_accuracy: 0.9867 - val_loss: 0.0480\n",
            "Epoch 7/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 115ms/step - accuracy: 0.9945 - loss: 0.0163 - val_accuracy: 0.9847 - val_loss: 0.0610\n",
            "Epoch 8/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 111ms/step - accuracy: 0.9935 - loss: 0.0198 - val_accuracy: 0.9871 - val_loss: 0.0546\n",
            "Epoch 9/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 128ms/step - accuracy: 0.9948 - loss: 0.0152 - val_accuracy: 0.9889 - val_loss: 0.0478\n",
            "Epoch 10/10\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 125ms/step - accuracy: 0.9956 - loss: 0.0135 - val_accuracy: 0.9851 - val_loss: 0.0740\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6d1a200b5cbb>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {test_acc:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    552\u001b[0m         )\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/My Drive/Colab Notebooks/Datasets/cats-vs-dogs.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall(path='./data2')\n",
        "  print('Done')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLcFPlAInM3S",
        "outputId": "88f205af-10a6-4ccd-aeaf-f5d19ac0c351"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# # Define data generators\n",
        "# train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "# validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# # def load_image(file_path):\n",
        "# #     try:\n",
        "# #         img = tf.io.read_file(file_path)\n",
        "# #         img = tf.image.decode_jpeg(img, channels=3)\n",
        "# #         return img\n",
        "# #     except Exception as e:\n",
        "# #         print(f\"Error loading image {file_path}: {e}\")\n",
        "# #         return None\n",
        "\n",
        "# train_generator = train_datagen.flow_from_directory(\n",
        "#     './data2/PetImages',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary',\n",
        "#     classes=['Cat', 'Dog'],\n",
        "#     subset='training',\n",
        "#     # load_function=load_image\n",
        "# )\n",
        "\n",
        "# validation_generator = validation_datagen.flow_from_directory(\n",
        "#     './data2/PetImages',\n",
        "#     target_size=(224, 224),\n",
        "#     batch_size=32,\n",
        "#     class_mode='binary',\n",
        "#     classes=['Cat', 'Dog'],\n",
        "#     subset='validation',\n",
        "#     # load_function=load_image\n",
        "# )\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "def data_generator(directory, batch_size, target_size):\n",
        "    while True:\n",
        "        batch_imgs = []\n",
        "        batch_labels = []\n",
        "        for folder in os.listdir(directory):\n",
        "            folder_path = os.path.join(directory, folder)\n",
        "            for file in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, file)\n",
        "                try:\n",
        "                    img = tf.io.read_file(file_path)\n",
        "                    img = tf.image.decode_jpeg(img, channels=3)\n",
        "                    img = tf.image.resize(img, target_size)\n",
        "                    label = 0 if folder == 'Cat' else 1\n",
        "                    batch_imgs.append(img)\n",
        "                    batch_labels.append(label)\n",
        "                    if len(batch_imgs) == batch_size:\n",
        "                        yield tf.stack(batch_imgs), tf.stack(batch_labels)\n",
        "                        batch_imgs = []\n",
        "                        batch_labels = []\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {file_path}: {e}\")\n",
        "\n",
        "train_generator = data_generator('./data2/PetImages', 32, (224, 224))\n",
        "validation_generator = data_generator('./data2/PetImages', 32, (224, 224))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=2,\n",
        "    validation_data=validation_generator,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(f'Test accuracy: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yUEsMkvbowxD",
        "outputId": "00ffffc2-e363-4087-a9ee-37f1d0ad7370"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "      3/Unknown \u001b[1m14s\u001b[0m 4s/step - accuracy: 0.3889 - loss: 10.7155Error loading image ./data2/PetImages/Cat/1937.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "      8/Unknown \u001b[1m32s\u001b[0m 4s/step - accuracy: 0.6603 - loss: 5.9570Error loading image ./data2/PetImages/Cat/8415.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     11/Unknown \u001b[1m44s\u001b[0m 4s/step - accuracy: 0.7255 - loss: 4.8138Error loading image ./data2/PetImages/Cat/4821.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     18/Unknown \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.8058 - loss: 3.4047Error loading image ./data2/PetImages/Cat/2742.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     19/Unknown \u001b[1m75s\u001b[0m 4s/step - accuracy: 0.8133 - loss: 3.2741Error loading image ./data2/PetImages/Cat/8295.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     23/Unknown \u001b[1m90s\u001b[0m 4s/step - accuracy: 0.8376 - loss: 2.8469Error loading image ./data2/PetImages/Cat/6376.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     38/Unknown \u001b[1m147s\u001b[0m 4s/step - accuracy: 0.8887 - loss: 1.9509Error loading image ./data2/PetImages/Cat/Thumbs.db: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "     43/Unknown \u001b[1m168s\u001b[0m 4s/step - accuracy: 0.8988 - loss: 1.7738Error loading image ./data2/PetImages/Cat/445.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     67/Unknown \u001b[1m258s\u001b[0m 4s/step - accuracy: 0.9285 - loss: 1.2534Error loading image ./data2/PetImages/Cat/7642.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     78/Unknown \u001b[1m300s\u001b[0m 4s/step - accuracy: 0.9367 - loss: 1.1106Error loading image ./data2/PetImages/Cat/5370.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     80/Unknown \u001b[1m309s\u001b[0m 4s/step - accuracy: 0.9379 - loss: 1.0883Error loading image ./data2/PetImages/Cat/6491.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     82/Unknown \u001b[1m316s\u001b[0m 4s/step - accuracy: 0.9391 - loss: 1.0670Error loading image ./data2/PetImages/Cat/3153.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     83/Unknown \u001b[1m319s\u001b[0m 4s/step - accuracy: 0.9397 - loss: 1.0567Error loading image ./data2/PetImages/Cat/8832.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     87/Unknown \u001b[1m334s\u001b[0m 4s/step - accuracy: 0.9420 - loss: 1.0176Error loading image ./data2/PetImages/Cat/3161.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     96/Unknown \u001b[1m369s\u001b[0m 4s/step - accuracy: 0.9464 - loss: 0.9401Error loading image ./data2/PetImages/Cat/23.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    102/Unknown \u001b[1m393s\u001b[0m 4s/step - accuracy: 0.9490 - loss: 0.8951Error loading image ./data2/PetImages/Cat/4629.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    117/Unknown \u001b[1m451s\u001b[0m 4s/step - accuracy: 0.9543 - loss: 0.8008Error loading image ./data2/PetImages/Cat/10874.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    122/Unknown \u001b[1m470s\u001b[0m 4s/step - accuracy: 0.9559 - loss: 0.7740Error loading image ./data2/PetImages/Cat/3197.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "Error loading image ./data2/PetImages/Cat/4334.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    125/Unknown \u001b[1m482s\u001b[0m 4s/step - accuracy: 0.9567 - loss: 0.7588Error loading image ./data2/PetImages/Cat/9208.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    133/Unknown \u001b[1m519s\u001b[0m 4s/step - accuracy: 0.9589 - loss: 0.7213Error loading image ./data2/PetImages/Cat/1757.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    135/Unknown \u001b[1m527s\u001b[0m 4s/step - accuracy: 0.9594 - loss: 0.7126Error loading image ./data2/PetImages/Cat/1151.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    171/Unknown \u001b[1m665s\u001b[0m 4s/step - accuracy: 0.9665 - loss: 0.5867Error loading image ./data2/PetImages/Cat/1267.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    173/Unknown \u001b[1m674s\u001b[0m 4s/step - accuracy: 0.9669 - loss: 0.5811Error loading image ./data2/PetImages/Cat/5077.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    177/Unknown \u001b[1m689s\u001b[0m 4s/step - accuracy: 0.9675 - loss: 0.5702Error loading image ./data2/PetImages/Cat/10404.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required. [Op:DecodeJpeg]\n",
            "    185/Unknown \u001b[1m720s\u001b[0m 4s/step - accuracy: 0.9686 - loss: 0.5498Error loading image ./data2/PetImages/Cat/3967.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    189/Unknown \u001b[1m735s\u001b[0m 4s/step - accuracy: 0.9692 - loss: 0.5401Error loading image ./data2/PetImages/Cat/6768.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    196/Unknown \u001b[1m761s\u001b[0m 4s/step - accuracy: 0.9701 - loss: 0.5241Error loading image ./data2/PetImages/Cat/8183.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    208/Unknown \u001b[1m808s\u001b[0m 4s/step - accuracy: 0.9716 - loss: 0.4988Error loading image ./data2/PetImages/Cat/11083.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    211/Unknown \u001b[1m820s\u001b[0m 4s/step - accuracy: 0.9719 - loss: 0.4929Error loading image ./data2/PetImages/Cat/4000.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    213/Unknown \u001b[1m829s\u001b[0m 4s/step - accuracy: 0.9721 - loss: 0.4891Error loading image ./data2/PetImages/Cat/2189.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    223/Unknown \u001b[1m867s\u001b[0m 4s/step - accuracy: 0.9732 - loss: 0.4707Error loading image ./data2/PetImages/Cat/1914.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    226/Unknown \u001b[1m879s\u001b[0m 4s/step - accuracy: 0.9735 - loss: 0.4655Error loading image ./data2/PetImages/Cat/7003.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    231/Unknown \u001b[1m898s\u001b[0m 4s/step - accuracy: 0.9739 - loss: 0.4571Error loading image ./data2/PetImages/Cat/4322.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    233/Unknown \u001b[1m907s\u001b[0m 4s/step - accuracy: 0.9741 - loss: 0.4538Error loading image ./data2/PetImages/Cat/5819.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    237/Unknown \u001b[1m922s\u001b[0m 4s/step - accuracy: 0.9745 - loss: 0.4474Error loading image ./data2/PetImages/Cat/11397.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    251/Unknown \u001b[1m976s\u001b[0m 4s/step - accuracy: 0.9757 - loss: 0.4265Error loading image ./data2/PetImages/Cat/1936.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "Error loading image ./data2/PetImages/Cat/6980.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    252/Unknown \u001b[1m979s\u001b[0m 4s/step - accuracy: 0.9758 - loss: 0.4250Error loading image ./data2/PetImages/Cat/3649.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    261/Unknown \u001b[1m1017s\u001b[0m 4s/step - accuracy: 0.9765 - loss: 0.4127Error loading image ./data2/PetImages/Cat/11095.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "Error loading image ./data2/PetImages/Cat/12235.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    262/Unknown \u001b[1m1020s\u001b[0m 4s/step - accuracy: 0.9765 - loss: 0.4114Error loading image ./data2/PetImages/Cat/6435.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    264/Unknown \u001b[1m1027s\u001b[0m 4s/step - accuracy: 0.9767 - loss: 0.4088Error loading image ./data2/PetImages/Cat/2021.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    265/Unknown \u001b[1m1032s\u001b[0m 4s/step - accuracy: 0.9768 - loss: 0.4075Error loading image ./data2/PetImages/Cat/2569.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    271/Unknown \u001b[1m1054s\u001b[0m 4s/step - accuracy: 0.9772 - loss: 0.3999Error loading image ./data2/PetImages/Cat/4351.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    274/Unknown \u001b[1m1066s\u001b[0m 4s/step - accuracy: 0.9774 - loss: 0.3963Error loading image ./data2/PetImages/Cat/12080.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    276/Unknown \u001b[1m1073s\u001b[0m 4s/step - accuracy: 0.9775 - loss: 0.3939Error loading image ./data2/PetImages/Cat/9100.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    278/Unknown \u001b[1m1082s\u001b[0m 4s/step - accuracy: 0.9777 - loss: 0.3915Error loading image ./data2/PetImages/Cat/3710.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    282/Unknown \u001b[1m1097s\u001b[0m 4s/step - accuracy: 0.9779 - loss: 0.3868Error loading image ./data2/PetImages/Cat/9619.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    286/Unknown \u001b[1m1113s\u001b[0m 4s/step - accuracy: 0.9782 - loss: 0.3823Error loading image ./data2/PetImages/Cat/6486.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    289/Unknown \u001b[1m1131s\u001b[0m 4s/step - accuracy: 0.9784 - loss: 0.3789Error loading image ./data2/PetImages/Cat/7647.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    301/Unknown \u001b[1m1178s\u001b[0m 4s/step - accuracy: 0.9791 - loss: 0.3662Error loading image ./data2/PetImages/Cat/9328.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    307/Unknown \u001b[1m1200s\u001b[0m 4s/step - accuracy: 0.9795 - loss: 0.3602Error loading image ./data2/PetImages/Cat/11086.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    309/Unknown \u001b[1m1209s\u001b[0m 4s/step - accuracy: 0.9796 - loss: 0.3582Error loading image ./data2/PetImages/Cat/7845.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    316/Unknown \u001b[1m1237s\u001b[0m 4s/step - accuracy: 0.9800 - loss: 0.3515Error loading image ./data2/PetImages/Cat/4929.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    319/Unknown \u001b[1m1248s\u001b[0m 4s/step - accuracy: 0.9801 - loss: 0.3487Error loading image ./data2/PetImages/Cat/10073.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    325/Unknown \u001b[1m1273s\u001b[0m 4s/step - accuracy: 0.9804 - loss: 0.3433Error loading image ./data2/PetImages/Cat/8553.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    329/Unknown \u001b[1m1288s\u001b[0m 4s/step - accuracy: 0.9806 - loss: 0.3398Error loading image ./data2/PetImages/Cat/11729.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    330/Unknown \u001b[1m1292s\u001b[0m 4s/step - accuracy: 0.9807 - loss: 0.3389Error loading image ./data2/PetImages/Cat/12269.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "Error loading image ./data2/PetImages/Cat/11864.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "    332/Unknown \u001b[1m1299s\u001b[0m 4s/step - accuracy: 0.9808 - loss: 0.3372"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e9a65750a21b>\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(validation_generator)\n",
        "print(f'Test accuracy: {test_acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "pCRO3Ud-y9Ok",
        "outputId": "cab23643-af71-452f-c8ff-05ea42cd3492"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3/Unknown \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00Error loading image ./data2/PetImages/Cat/1937.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "      8/Unknown \u001b[1m10s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00Error loading image ./data2/PetImages/Cat/8415.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     11/Unknown \u001b[1m14s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00Error loading image ./data2/PetImages/Cat/4821.jpg: {{function_node __wrapped__DecodeJpeg_device_/job:localhost/replica:0/task:0/device:CPU:0}} Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodeJpeg [Op:DecodeJpeg]\n",
            "     14/Unknown \u001b[1m17s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0000e+00"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-da6d033e59e2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test accuracy: {test_acc:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This clearly showing the model is working really great but due to time and space constraints the whole epoch might not be possible"
      ],
      "metadata": {
        "id": "EwvdJ2oCzDkr"
      }
    }
  ]
}