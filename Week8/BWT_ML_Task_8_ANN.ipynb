{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install Required Libraries:\n",
        "This cell installs Keras Tuner, a library for hyperparameter optimization of Keras models."
      ],
      "metadata": {
        "id": "WjnaggF51Rcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "217F2U-RzOHd",
        "outputId": "a98d4ea9-d00e-445d-f150-ab295be7c5fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/129.1 kB\u001b[0m \u001b[31m958.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries:\n",
        "This cell imports the necessary libraries, including Keras for building neural networks, Keras Tuner for hyperparameter tuning, and scikit-learn for data preprocessing and evaluation metrics."
      ],
      "metadata": {
        "id": "4wX94tHC1S6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGVrs1ZdwFcg",
        "outputId": "a0f1d3e6-7979-4c10-bee5-24906f518178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-25376277e413>:10: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
        "from sklearn.datasets import load_digits\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l2\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Preprocess the MNIST Dataset:\n",
        "The MNIST dataset is loaded from sklearn.datasets. The data is split into training and test sets, and the features are standardized using StandardScaler."
      ],
      "metadata": {
        "id": "EugQg6ex1VbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = load_digits()\n",
        "\n",
        "\n",
        "# Pandas data frame with feature vectors\n",
        "X = mnist.data\n",
        "\n",
        "# Labels\n",
        "y = mnist.target\n",
        "\n",
        "# Labels converted to integers\n",
        "y = y.astype(int)\n",
        "print(\"Feature vectors shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AXqKYyMx5rS",
        "outputId": "c04486cf-83b3-4747-f2d3-3cace7a676eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature vectors shape: (1797, 64)\n",
            "Labels shape: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the data for SVC and Logistic Regression\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kIgdoIJ3x_kN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the Model Building Function:\n",
        "This function defines a model-building function compatible with Keras Tuner. It includes an adjustable number of units in the first Dense layer and an L2 regularization parameter. The output layer uses a softmax activation function to classify the digits."
      ],
      "metadata": {
        "id": "EBK51JkN1ZXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_shape=(64,), kernel_regularizer=l2(hp.Float('l2', min_value=0.001, max_value=0.1, step=0.01))))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "qlbIXcTWy_nk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning Using Random Search:\n",
        "Keras Tuner's RandomSearch is used to search for the best hyperparameters. The tuning is performed over 10 trials, with 3 executions per trial, optimizing for validation accuracy."
      ],
      "metadata": {
        "id": "TNmQwf9o1btm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=3,\n",
        "    directory='my_dir',\n",
        "    project_name='helloworld')\n",
        "\n",
        "tuner.search(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30uIEwyYzAO4",
        "outputId": "bcb6e96f-5591-4cab-fc3b-ff80807275f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.9675925771395365\n",
            "\n",
            "Best val_accuracy So Far: 0.9814814726511637\n",
            "Total elapsed time: 00h 04m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrieve and Evaluate the Best Model:\n",
        "The best model identified by Keras Tuner is retrieved and evaluated on the test set."
      ],
      "metadata": {
        "id": "zQ19sLjB1eDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_T0PNBdzDMN",
        "outputId": "864cf4c6-df71-4e14-fd14-bc856b635435"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Report and Confusion Matrix:\n",
        "The predictions on the test set are used to generate a classification report and confusion matrix, providing detailed metrics for the model's performance."
      ],
      "metadata": {
        "id": "kyIGy8Im1g9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model\n",
        "loss, accuracy = best_model.evaluate(X_test_scaled, y_test)\n",
        "print('Test accuracy:', accuracy)\n",
        "\n",
        "# Print classification report and confusion matrix\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred_class))\n",
        "print(confusion_matrix(y_test, y_pred_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMFzTo5IzGWC",
        "outputId": "45c53386-b8b9-4fe7-b02a-2ed476f39448"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9870 - loss: 0.1740 \n",
            "Test accuracy: 0.9833333492279053\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        33\n",
            "           1       1.00      1.00      1.00        28\n",
            "           2       1.00      1.00      1.00        33\n",
            "           3       1.00      0.97      0.99        34\n",
            "           4       1.00      1.00      1.00        46\n",
            "           5       0.98      0.94      0.96        47\n",
            "           6       0.97      0.97      0.97        35\n",
            "           7       1.00      0.97      0.99        34\n",
            "           8       1.00      1.00      1.00        30\n",
            "           9       0.93      1.00      0.96        40\n",
            "\n",
            "    accuracy                           0.98       360\n",
            "   macro avg       0.99      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n",
            "[[33  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 28  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 33  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 33  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 46  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 44  1  0  0  2]\n",
            " [ 1  0  0  0  0  0 34  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 33  0  1]\n",
            " [ 0  0  0  0  0  0  0  0 30  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 40]]\n"
          ]
        }
      ]
    }
  ]
}